{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0907ec7",
   "metadata": {},
   "source": [
    "# LangChain 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a80ce4",
   "metadata": {},
   "source": [
    "## 1. LangChain이란?\n",
    "\n",
    " - LangChain은 LLM(거대 언어 모델)을 활용하여 실제 애플리케이션을 쉽고 강력하게 구축할 수 있도록 도와주는 프레임워크입니다. \n",
    " - 단순히 모델을 호출하는 것을 넘어, 데이터 연결, 에이전트 생성, 체인 구성 등 LLM 애플리케이션에 필요한 다양한 기능을 모듈화하여 제공합니다.\n",
    "### 핵심 정의\n",
    "- LLM 기반 애플리케이션의 전체 라이프사이클을 단순화\n",
    "- 개발부터 배포까지 종합적인 솔루션 제공\n",
    "- 다양한 LLM 제공업체와의 표준화된 인터페이스 구현\n",
    "\n",
    "#### 우리가 주로 사용할 LangChain 모듈들\n",
    "1. PromptTemplate\n",
    "2. OutputParser\n",
    "3. Model\n",
    "4. DocumentLoader\n",
    "5. TextSpliter\n",
    "6. Embedding\n",
    "7. VectorStore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f1409",
   "metadata": {},
   "source": [
    "### 기본 사용 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47ad1c",
   "metadata": {},
   "source": [
    "#### 1. API 키 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 환경변수 값 확인\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "print(f\"OPENAI_API_KEY가 설정되어 있나요?: {openai_api_key[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75235f99",
   "metadata": {},
   "source": [
    "#### 2. 채팅 모델 초기화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b722601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# model provider : 모델 제공사\n",
    "# temperature : 창의성 정도\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.5)\n",
    "\n",
    "print(\"모델이 성공적으로 초기화되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e54f4a",
   "metadata": {},
   "source": [
    "#### 3.LLM 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 메시지 전송\n",
    "# invoke : 실행명령어\n",
    "response = llm.invoke(\"안녕하세요! LangChain에 대해 간단히 설명해주세요.\")\n",
    "\n",
    "print(\"AI 응답:\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e6ca7",
   "metadata": {},
   "source": [
    "\n",
    "#### AIMessage\n",
    "- LangChain에서 LLM 호출 시 `AIMessage` 객체가 반환됩니다. \n",
    "- LangChain 프레임워크에서 AI 언어 모델이 생성한 메시지를 나타내는 데이터 구조(클래스)입니다.\n",
    "---\n",
    "**주요 구성 요소**\n",
    "1. content\n",
    "- 모델이 실제로 생성한 답변 텍스트\n",
    "2. additional_kwargs\n",
    "- 부가 옵션 (예: 거부 여부 `refusal`)\n",
    "3. response_metadata\n",
    "- 모델 관련 상세 정보\n",
    "  - 사용된 모델 이름 (`model_name`)\n",
    "  - 토큰 사용량 (`prompt_tokens`, `completion_tokens`, `total_tokens`)\n",
    "  - 응답 종료 이유 (`finish_reason`)\n",
    "4. usage_metadata\n",
    "- LangChain이 정리한 토큰 사용량 요약\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10538b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04787a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe22cf3",
   "metadata": {},
   "source": [
    "## 2.LCEL (Langchain Chain Expression Language)\n",
    "**LCEL이란?**\n",
    "- Langchain에서 프롬프트, 체인, LLM 호출 등 다양한 구성요소를 함수형으로 조합할 수 있음.\n",
    "- 파이프라인처럼 여러 단계를 연결하여 복잡한 워크플로우를 간결하게 체인형태로 구현할 수 있다.\n",
    "- 각 단계는 함수(또는 객체)로 표현되며, 입력과 출력을 연결 가능하다.\n",
    "- 예시: (프롬프트 → LLM → 후처리) 과정을 한 줄로 연결하여 작성 가능합니다\n",
    "- `chain = prompt | model | output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{input}가 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 만들기\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c556453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저 입력\n",
    "input = \"Retrieval\"\n",
    "\n",
    "# 응답 출력\n",
    "response = chain.invoke(input)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0ab26",
   "metadata": {},
   "source": [
    "### 공식 리소스\n",
    "- **공식 문서**: [python.langchain.com](https://python.langchain.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test0116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
